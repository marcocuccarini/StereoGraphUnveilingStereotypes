# StereoGraph

**"Unveiling Stereotypes: StereoGraph-Enhanced LLMs for Knowledge-Driven Stereotype Explanation"**  
Presented at **CLIC-it 2025**

StereoGraph is a framework designed to enhance Large Language Models (LLMs) with structured knowledge for the detection and explanation of stereotypes. This repository contains all the code, data, and documentation needed to reproduce the experiments from the paper.

---

## ðŸš€ Features

- Combines LLMs with knowledge graphs for stereotype explanation
- Supports models like **Gemma**, **LLaMA**, and **Mistral** (via [Ollama](https://ollama.ai))
- Human and automated evaluation modules
- Jupyter-compatible pipeline for analysis and experimentation

---

## ðŸ’  Installation

### 1. Clone the repository
```bash
git clone https://github.com/marcocuccarini/StereoGraphUnveilingStereotypes.git
cd StereoGraphUnveilingStereotypes
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```

### 3. Install Ollama
Follow the official installation instructions from [ollama.ai](https://ollama.ai).


### 4. Import the dataset 
From the following GitHub page: [Open-Stereotype-corpus](https://github.com/SodaMaremLo/Open-Stereotype-corpus) and import into the test_graph_creation, with the name "stereo_test.csv".
Rember to split the dataset using the samples (ids) present in the dataset test_set.csv". 

### 5. Run the code main.py
It save the results om script, result_evalaution results

### 6. Run the evalaute_perfroamnce.py update the json fil, adding the avarege results in the fon of thejson file



---

## ðŸ“‚ Repository Structure

```
StereoGraph/
â”‚
â”œâ”€â”€ data/                              # Dataset folders
â”‚   â”œâ”€â”€ error analysis/                # IDs and human annotations for error analysis
â”‚   â””â”€â”€ test e graph creation/         # Dataset and IDs used for graph creation and testing
â”‚
â”œâ”€â”€ human_evaluation/                  # Human evaluation results (error and similarity analyses)
â”‚
â”œâ”€â”€ kg/                                # Populated knowledge graph (ontology instances)
â”‚
â”œâ”€â”€ ontology/                          # Ontology schema used in experiments
â”‚
â”œâ”€â”€ scripts/                           # Scripts for pipeline execution and evaluation
â”‚   â”œâ”€â”€ pipeline_implementation/       # Core pipeline components
â”‚   â”‚   â”œâ”€â”€ main.py                    # Script to run and test the model
â”‚   â”‚   â””â”€â”€ prompt.py                  # List of possible prompts for evaluation
â”‚   â”‚
â”‚   â”œâ”€â”€ results_evaluation/           # Evaluation outputs and utilities
â”‚   â”‚   â””â”€â”€ evaluate_performance.py    # Extracts average similarity from result files
â”‚
â”œâ”€â”€ src/                               # SPARQL queries and related utilities
â”‚
â”œâ”€â”€ main.py                            # CLI entry point for the full pipeline
â””â”€â”€ prompts.py                         # Prompt templates used in the evaluation

```

---

## ðŸš€ Running the Pipeline

Run the experiment using either of the following:

### Option 1: Python script
```bash
python main.py
```

### Option 2: Jupyter Notebook
Open `main.ipynb` and run all cells.

The system runs experiments using three LLMs: **Gemma**, **LLaMA**, and **Mistral**. It processes a triple-stereotype dataset and can be extended to any model available via **Ollama**.

---

## ðŸ“š Data

- `data/error analysis/`: IDs and human annotations used in error analysis
- `data/test e graph creation/`: Dataset used to create the knowledge graph and for testing
- `human_evaluation/`: Contains the results of human evaluations

---

## ðŸ”— Contribution

We welcome contributions! Please open issues or submit pull requests if you find bugs or want to improve the project.

---

## ðŸ“– Citation

If you use this work, please cite the following paper:

> **Unveiling Stereotypes: StereoGraph-Enhanced LLMs for Knowledge-Driven Stereotype Explanation**  
> CLIC-it 2025

(Citation BibTeX coming soon)

---

## ðŸš« License

This project is licensed under the MIT License. See `LICENSE` for details.

